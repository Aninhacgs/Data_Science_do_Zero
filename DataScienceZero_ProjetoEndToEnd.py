# -*- coding: utf-8 -*-
"""AqueceMaratona2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BUAaVsSvhhN_yD6jzmU5S_lHqWyAxAq7

# AQUECE MARATONA 2020! 

*   LOTE 1 ( 52,00 ) https://www.qoda.com.br/maratona-data-science-pre-venda/
*   LOTE 2 ( 102,00 )
*   LOTE 3 ( 222,00 )
*   LOTE FINAL ( 992,00 )




---
![](http://uploaddeimagens.com.br/images/002/534/509/full/Sem_t%C3%ADtulo.png?1584024855)


---
![alt text](https://www.qoda.com.br/wp-content/uploads/2020/02/timeline-maratona.png)

*   LOTE 1 ( 52,00 ) https://www.qoda.com.br/maratona-data-science-pre-venda/
*   LOTE 2 ( 102,00 )
*   LOTE 3 ( 222,00 )
*   LOTE FINAL ( 992,00 )

# Python: o básico!
"""

print("Hello Qoda!")

# Comentando código e declarando variáveis? EASY!
nome = input("Qual é o seu nome? ")
print(f"Oi, {nome}")

!pip install pandas
!pip install numpy

import pandas as pd
import numpy as np

"""# END TO END

---

Projeto que passa por todas etapas de um projeto Data Science.<br><br>
![alt text](https://miro.medium.com/max/377/1*_fR-2Yg-xaWXssnj08Zqeg.jpeg)

## PREPARE DATA

---

### AQUISIÇÃO DE DADOS

---

https://www.kaggle.com/camnugent/california-housing-prices
"""

from google.colab import files
files.upload()

"""### CLASSIFICAÇÃO VS. REGRESSÃO

---
![alt text](https://www.researchgate.net/profile/Yves_Matanga2/publication/326175998/figure/fig9/AS:644582983352328@1530691967314/Classification-vs-Regression.png)

### INDICADORES DE DESEMPENHO

---

Para problemas de regressão utilizamos comumente o RMSE(raiz do erro quadrático médio).
Para maiores informações acesse http://www-di.inf.puc-rio.br/~lopes//inf2391/Data_Science_Learning2.pdf

### ANÁLISE EXPLORATÓRIA DOS DADOS
"""

housing = pd.read_csv('housing.csv')
housing.head()

# 10 features, sendo cada linha um distrito
# 20.639 amostras
housing.info()

# Única feature não-numérica
housing["ocean_proximity"].value_counts()

# Resumo numérico, "total_bedrooms" nos mostra alguns desafios
# SKILL NECESSÁRIA: Probabilidade/Estatística
housing.describe()

# SKILL NECESSÁRIA: Probabilidade/Estatística, Dataviz, Análise de Dados
import matplotlib.pyplot as plt
housing.hist(bins=50, figsize=(20,15))
plt.show()

"""1. **"median_income"** não está expressa em dólares, sendo 15000 o valor para RENDA ALTA e 0,5 o valor para RENDA BAIXA
2. **"housing_median_age"** possui valores "estranhos", assim como **"housing_medium_value"**(target). Pode ser necessário coletar dados melhores ou remover amostras
3. Atributos estão em escalas diferentes: não em dólar, ano...
4. Aplicar modelos preditivos agora pode ser um grande problema: note que alguns histogramas apresentam cauda longa a direita, enquanto outros não(pode dificultar a generalização).

### PREPARAÇÃO DOS DADOS

### TRAIN/TEST SPLIT

---

![alt text](data:image/png;base64,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)
"""

!pip install scikit-learn

from sklearn import datasets
iris = datasets.load_iris()
digits = datasets.load_digits()

from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)

test_set.head()

housing["median_income"].hist()

""""median_incoming" está agrupada em torno de 2 a 5 (dezenas de milhares de dólares), mas algumas rendas medianas vão muito além de 6. Isto pode enviesar nossos dados, ou seja, forçar uma tendência na hora da predição. Estratificar dados se faz necessário para que as amostras coletadas sejam proporcionais. Utilizaremos numpy para normalizar estes dados e criar novas features.

### FEATURE ENGINEERING
"""

import numpy as np
housing["income_cat"] = np.ceil(housing["median_income"] / 1.5)
housing["income_cat"].where(housing["income_cat"] < 5, 5.0, inplace=True)

from sklearn.model_selection import StratifiedShuffleSplit #estratificação
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

for train_index, test_index in split.split(housing, housing["income_cat"]):
 strat_train_set = housing.loc[train_index]
 strat_test_set = housing.loc[test_index]

# Dividimos os valores pelo tamanho do dataset e assim verificamos as proporções de "income_cat"
housing["income_cat"].value_counts() / len(housing)

"""### DATAVIZ"""

housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.1) #alpha se refere a densidade dos pontos

# A localização afeta o preço destes imóveis? 
housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4,
 s=housing["population"]/100, label="population",
 c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True,)
plt.legend()

# Suficiente para uma correlação? valores entre -1 a 1, onde 1 significa CORRELAÇÃO POSITIVA FORTE
# Coeficiente de correlação de Pearson
corr_matrix = housing.corr()
corr_matrix["median_house_value"].sort_values(ascending=False)

# Correlação com PANDAS
from pandas.plotting import scatter_matrix
attributes = ["median_house_value", "median_income", "total_rooms","housing_median_age"]
scatter_matrix(housing[attributes], figsize=(12, 8))

"""### DATA CLEANING"""

# Removendo nossa target dos dados de TREINO
housing = strat_train_set.drop("median_house_value", axis=1) 
housing_labels = strat_train_set["median_house_value"].copy() # realizamos uma cópia e armazenamos na variável "housing_labels"

# Verificando dados ausentes
sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()
sample_incomplete_rows

# Utilizando Simple Imputer https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html
from sklearn.impute import SimpleImputer 
imputer = SimpleImputer(strategy="median")

# Limpando dados ausentes(missing values)
sample_incomplete_rows.drop("total_bedrooms", axis=1)  
median = housing["total_bedrooms"].median()

# Removemos a categoria não-numérica
housing_num = housing.drop('ocean_proximity', axis=1)

imputer.fit(housing_num)

# Transformaremos agora o conjunto TREINO com missing values substituidos pela mediana
X = imputer.transform(housing_num)

housing_tr = pd.DataFrame(X, columns=housing_num.columns,index=housing.index)
housing_tr.head()

"""***Estimadores:*** Qualquer objeto que possa estimar alguns parâmetros com base em um conjunto de dados é chamado de estimador (por exemplo, um imputador é um estimador). A estimativa em si é realizada pelo método fit() e utiliza apenas um conjunto de dados como parâmetro (ou dois para algoritmos de aprendizado supervisionado; o segundo conjunto de dados contém os rótulos). Qualquer outro parâmetro necessário para orientar o processo de estimativa é considerado um hiperparâmetro (como a estratégia de um imputador) e deve ser definido como uma variável de instância (geralmente via parâmetro construtor).

---

***Transformadores:*** Alguns estimadores (como um imputador) também podem transformar um conjunto de dados; estes são chamados de transformadores. Mais uma vez, a API é bastante simples: a transformação é realizada pelo método transform() com o conjunto de dados para transformar como parâmetro. Retorna o conjunto de dados transformado. Essa transformação geralmente depende dos parâmetros aprendidos, como é o caso de um imputador. Todos os transformadores também têm um método de conveniência chamado fit_transform()
"""

# PRÉ PROCESSAMENTO DA FEATURE CATEGORICA "ocean_proximity"
housing_cat = housing[['ocean_proximity']]
housing_cat.head()

# Lidando com dados NÃO-NUMÉRICOS 
# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
housing_cat = housing["ocean_proximity"]
housing_cat_encoded = encoder.fit_transform(housing_cat)
housing_cat_encoded

# BINARIZAR
# É possível transformar inteiros em categorias, assim como categorias em números inteiros
from sklearn.preprocessing import LabelBinarizer
encoder = LabelBinarizer()
housing_cat_1hot = encoder.fit_transform(housing_cat)
housing_cat_1hot

# ONE HOT ENCODER
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder()
housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))
housing_cat_1hot

encoder.categories_

housing.columns

"""### TRANSFORMAÇÃO CUSTOMIZADA

---

Feature Scaling é uma das mais importantes transformações de dados disponível, sendo geralmente dividida em "Min/Max scaling" e "Standardization".

### MIN/MAX SCALING
Os valores são alterados e redimensionados para que acabem variando de 0 a 1. Fazemos isso subtraindo o valor mínimo e dividindo pelo máximo menos o mínimo. O Scikit-Learn fornece um transformador chamado MinMaxScaler para isso. Ele possui um hiperparâmetro feature_range que permite alterar o intervalo, se você não quiser de 0 a 1 por algum motivo.

### STANDARDIZATION
Diferentemente da escala min-max, a padronização não vincula valores a um intervalo específico, o que pode ser um problema para alguns algoritmos (por exemplo, redes neurais geralmente esperam um valor de entrada que varia de 0 a 1). No entanto, a padronização é muito menos afetada pelos valores discrepantes. Por exemplo, suponha que um distrito tenha uma renda mediana igual a 100 (por engano). A escala Min-max esmagaria todos os outros valores de 0 a 15 para 0 a 0,15, enquanto a padronização não seria muito afetada. O Scikit-Learn fornece um transformador chamado StandardScaler para padronização.

Neste exemplo, o transformador possui um hiperparâmetro, add_bedrooms_per_room, definido como True por padrão (geralmente é útil fornecer padrões sensíveis). Esse hiperparâmetro permitirá que você descubra facilmente se a adição desse atributo ajuda os algoritmos de Machine Learning ou não. De maneira mais geral, você pode adicionar um hiperparâmetro para bloquear qualquer etapa de preparação de dados que você não tem 100% de certeza. Quanto mais você automatizar essas etapas de preparação de dados, mais combinações você pode experimentar automaticamente, aumentando a probabilidade de encontrar uma ótima combinação (e economizando muito tempo).
"""

# Maiores infos em https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html?highlight=baseestimator#sklearn.base.BaseEstimator
# Maiores infos em https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html?highlight=transformermixin#sklearn.base.TransformerMixin

from sklearn.base import BaseEstimator, TransformerMixin

# Índices das colunas com list comprehension
rooms_ix, bedrooms_ix, population_ix, household_ix = [list(housing.columns).index(col) for col in ("total_rooms", "total_bedrooms", "population", "households")]

class CombinedAttributesAdder(BaseEstimator, TransformerMixin):
    
    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs
        self.add_bedrooms_per_room = add_bedrooms_per_room
    
    def fit(self, X, y=None):
        return self  # nothing else to do
    
    def transform(self, X, y=None):
        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]
        population_per_household = X[:, population_ix] / X[:, household_ix]
        if self.add_bedrooms_per_room:
            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household,
                         bedrooms_per_room]
        else:
            return np.c_[X, rooms_per_household, population_per_household]

attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)
housing_extra_attribs = attr_adder.transform(housing.values)

from sklearn.preprocessing import FunctionTransformer

def add_extra_features(X, add_bedrooms_per_room=True):
    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]
    population_per_household = X[:, population_ix] / X[:, household_ix]
    if add_bedrooms_per_room:
        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
        return np.c_[X, rooms_per_household, population_per_household,
                     bedrooms_per_room]
    else:
        return np.c_[X, rooms_per_household, population_per_household]

attr_adder = FunctionTransformer(add_extra_features, validate=False,
                                 kw_args={"add_bedrooms_per_room": False})
housing_extra_attribs = attr_adder.fit_transform(housing.values)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

num_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy="median")),
        ('attribs_adder', CombinedAttributesAdder(add_extra_features)),
        ('std_scaler', StandardScaler()),
    ])

housing_num_tr = num_pipeline.fit_transform(housing_num)

from sklearn.compose import ColumnTransformer

num_attribs = list(housing_num)
cat_attribs = ["ocean_proximity"]

full_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs),
        ("cat", OneHotEncoder(), cat_attribs),
    ])

housing_prepared = full_pipeline.fit_transform(housing)
housing_prepared

from sklearn.base import BaseEstimator, TransformerMixin

class DataFrameSelector(BaseEstimator, TransformerMixin):
 
 def __init__(self, attribute_names):
   self.attribute_names = attribute_names
 
 def fit(self, X, y=None):
   return self
 
 def transform(self, X):
   return X[self.attribute_names].values

"""O Pipeline faz uma lista de pares nome/estimador, definindo uma sequência de etapas. Todos, exceto o último estimador, devem ser transformadores (ou seja, eles devem ter um método "fit_transform()"). Os nomes podem ser o que você quiser. Quando você chama o método fit() do pipeline, ele chama fit_transform() sequencialmente em todos os transformadores, passando a saída de cada chamada como parâmetro para a próxima chamada, até atingir o estimador final, para o qual chama apenas método fit()."""

housing_num_tr

"""Agora você tem um pipeline para valores numéricos e também precisa aplicar o LabelBinarizer nos valores categóricos: como você pode unir essas transformações em um único pipeline? O Scikit-Learn fornece uma classe FeatureUnion para isso. Você fornece uma lista de transformadores(que podem ser Pipelines). O método transform() é chamado de cada transformador em paralelo, aguardando a sua saída e concatenando-os, retornando o resultado."""

housing_prepared

"""### MODELO PREDITIVO(TREINO)"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, housing_labels)

# let's try the full preprocessing pipeline on a few training instances
some_data = housing.iloc[:5]
some_labels = housing_labels.iloc[:5]
some_data_prepared = full_pipeline.transform(some_data)

print("Predictions:", lin_reg.predict(some_data_prepared))

print("Labels:", list(some_labels))

from sklearn.metrics import mean_squared_error

housing_predictions = lin_reg.predict(housing_prepared)
lin_mse = mean_squared_error(housing_labels, housing_predictions)
lin_rmse = np.sqrt(lin_mse)
lin_rmse

"""Nosso modelo esta errando em, aproximadamente, $68.376,64! Temos agora um exemplo claro de UNDERFITTING<br><br>![alt text](https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1526498075543.png)
<br><br>
Quando isso acontece, pode significar que os recursos não fornecem informações suficientes para fazer boas previsões ou que o modelo não é poderoso o suficiente. O que fazer?
*   Selecionar modelo mais poderoso, outro algoritmo...
*   Reduzir restrições no modelo/adicionar novas features.
"""

# Tentaremos com novo algoritmo, diferente da REGRESSÃO LINEAR

from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor(random_state=42)
tree_reg.fit(housing_prepared, housing_labels)

housing_predictions = tree_reg.predict(housing_prepared)
tree_mse = mean_squared_error(housing_labels, housing_predictions)
tree_rmse = np.sqrt(tree_mse)
tree_rmse

"""Uau! modelo perfeito?! Não! Agora temos o OVERFITTING!
![alt text](https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1526498075543.png)

### CROSS-VALIDATION!
![alt text](https://miro.medium.com/max/1368/0*P--gozwUfJ0TKtEp.png)
"""

# UTILIZANDO DECISIONTREEREGRESSOR
from sklearn.model_selection import cross_val_score

scores = cross_val_score(tree_reg, housing_prepared, housing_labels,
                         scoring="neg_mean_squared_error", cv=10)

tree_rmse_scores = np.sqrt(-scores)

def display_scores(scores):
    print("Scores:", scores)
    print("Mean:", scores.mean())
    print("Standard deviation:", scores.std())

display_scores(tree_rmse_scores)

# UTILIZANDO LINEARREGRESSION
lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,
                             scoring="neg_mean_squared_error", cv=10)
lin_rmse_scores = np.sqrt(-lin_scores)
display_scores(lin_rmse_scores)

# TENTAREMOS COM OUTRO ALGORITMO: RANDOMFORESTREGRESSOR
from sklearn.ensemble import RandomForestRegressor
forest_reg = RandomForestRegressor()
forest_reg.fit(housing_prepared, housing_labels)
housing_predictions = forest_reg.predict(housing_prepared)
forest_mse = mean_squared_error(housing_labels, housing_predictions)
forest_rmse = np.sqrt(forest_mse)
forest_rmse

from sklearn.model_selection import cross_val_score

forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,
                                scoring="neg_mean_squared_error", cv=10)
forest_rmse_scores = np.sqrt(-forest_scores)
display_scores(forest_rmse_scores)

"""### FINE-TUNE MODEL ou AJUSTES DE PARÂMETROS

---

Uma maneira de fazer isso seria mexer nos hiperparâmetros manualmente, até encontrar uma ótima combinação de valores de hiperparâmetros. Isso seria um trabalho muito tedioso e talvez você não tenha tempo para explorar muitas combinações. Em vez disso, você deve fazer com que o GridSearchCV do Scikit-Learn o procure. Tudo o que você precisa fazer é dizer com quais hiperparâmetros você deseja experimentar e quais valores testar e avaliará todas as combinações possíveis de hiperparâmetro, usando validação cruzada. Por exemplo, o código a seguir procura a melhor combinação de valores de hiperparâmetro para o RandomForestRegressor:
"""

from sklearn.model_selection import GridSearchCV
param_grid = [
 {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},
 {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
 ]
forest_reg = RandomForestRegressor()
grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
 scoring='neg_mean_squared_error')
grid_search.fit(housing_prepared, housing_labels)

grid_search.best_params_

grid_search.best_estimator_

cvres = grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
  print(np.sqrt(-mean_score), params)

"""### EVALUATE MODEL ou AVALIAÇÃO DOS MODELOS

---

Depois de ajustar seus modelos por um tempo, você finalmente terá um sistema com desempenho suficiente. Agora é a hora de avaliar o modelo final no conjunto de testes. Não há nada de especial nesse processo; basta obter os preditores e os rótulos do seu conjunto de testes, execute seu full_pipeline para transformar os dados (chamada transform(), não fit_transform ()) e avalie o modelo final no conjunto de testes
"""

final_model = grid_search.best_estimator_
X_test = strat_test_set.drop("median_house_value", axis=1)
y_test = strat_test_set["median_house_value"].copy()
X_test_prepared = full_pipeline.transform(X_test)
final_predictions = final_model.predict(X_test_prepared)
final_mse = mean_squared_error(y_test, final_predictions)
final_rmse = np.sqrt(final_mse)

final_rmse

"""O desempenho geralmente será um pouco pior do que você mediu usando a validação cruzada se você fez muitos ajustes de hiperparâmetro (porque seu sistema acaba sendo ajustado para ter um bom desempenho nos dados de validação e provavelmente não terá um bom desempenho em conjuntos de dados desconhecidos). Agora vem a fase de pré-lançamento do projeto: você precisa apresentar sua solução (destacar o que aprendeu, o que funcionou e o que não funcionou, que suposições foram feitas e quais são as limitações do seu sistema), documentar tudo e criar boas apresentações com visualizações claras e declarações fáceis de lembrar (por exemplo, “median_income" é o preditor número um dos preços da habitação”).

## Referências bibliográficas<br>
https://github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb<br><br>
![alt text](https://m.media-amazon.com/images/S/aplus-media/vc/399b38c4-ae00-4ca3-b01f-4d482ab4cdeb.__CR133,0,1064,1418_PT0_SX300_V1___.png)

# DATASET PRÉ-PRONTO

---
![alt text](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxMTEhUTExQVFhUXGB0YGBcYGBgeGBoeHxsgIB0YGB0YHSggGRslHh4XITEhJSorLjAuGB8zODMtNygtLisBCgoKDg0OGxAQGy8lICYtLy0tLS0tLS0tLS0vLS0tNS8tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLf/AABEIAIkBbwMBIgACEQEDEQH/xAAcAAACAgMBAQAAAAAAAAAAAAAFBgQHAAMIAgH/xABSEAACAQIDBQQFBwgGBwYHAAABAhEAAwQSIQUGEzFBIlFhcQcygZGhFCNCUrHB0TNicpKT0uHwFiQ0U1RjFUNEc4KywyWEotPi8RcmNWSDs8L/xAAaAQACAwEBAAAAAAAAAAAAAAACAwABBAUG/8QALBEAAgIBBAEEAAYCAwAAAAAAAAECEQMEEiExQRMiUWEUcYGhsfCR0QUkMv/aAAwDAQACEQMRAD8AvBjAmkSz6XtksYF9yf8Ac3f3aeb3qnyNcW2rRABiDVMh06PSxsvNl4zg8tbN0DzJywB40d/pVhvrN+q34VysbwZST60RT5uLtsMowztJUDhseo/uz4jp4adNUznJK0U7SLsfevDAE5mMCdEYn2CNTQc+lLZv96/7G7+7SzFV/v3sdrVwYhJ4TmHA5K34NzHjPhQQzSk6BUmy4rnpZ2WOd5/2N392vC+l7ZJIHHceJs3Y8z2eVc+vbgRqQWGvPpWsbPedFPu0p2/5DOltpekPAWApuXHytyZbdxlOkjVQRqNR39KjYP0pbMutlS689xtXR9q1TG7aObTYa+JtsOwCdR1K+AnUdxHjpu2PsJbDuXbPHZUctDHOOv4GqwueWTgqv9irvhFu4r0s7LtsUe7cDDobN392vielnZZ5Xbn7C9+7VXbR2dZeCEnUAAmYB6qTqvTTke6heI2UASJbQxyA7+/TSOfiK0Sw5k623/BHZc7+lfZY53n/AGN392tuB9J+zbxYW7rsVExwrgJA5wCuvkKpNNj4c+ujP4s7D/kIFbE3cTOtzD3HtMpkAwwB+2POaOWlzKN8WXTLsw/pI2e+bLcc5efzVz711rSnpR2aTAuvMx+Ru/u1Vt/AtbbjqBDD5xRynkSvgaWdsW+FfXSVbtKfOues0m6A3MvZ/SrswNlN25PL8jd+3LRi3vfhWiHbUT6jfhXOtjB8XEov0TDHy5n8PbTztHFG3auXVEkLCjxiBH20M9RJUkTcy0dmb4YS+uIa1cJXDCbpKOMohjpI7WitynlQu36UNmHlfY//AIrv7tV16Ln/AOz9smdfk+v7K9SRgcOcgj306U2kmGuuS/r3pN2aq5mvMB/urv3LWWfSZs1gGF5oP+VdH2rVEnZ2b1jPcKj4rCXVBUcuYih9ZsnB0T/TvA/3jfs7n7tRL/pL2chytdcEf5N37lqkMLiriJDNJoRjMWWPf41Ucs2/BUbZf7+lfZY0N5/2F79yvjeljZQ/17/sL37lc9M1ZbtTrTd4dHQZ9Lmyf79/2F/9yvdv0r7LJAF9+0YHzN7vj6mlUZgsGt20yiOJbOYeIPMe+heIuAKCOanl+NCst8FJHR2P9JmzbJAuXXEiRFm6esdFrSnpV2WeV64dJ/IXv3Kp/beJN2wltV7Vzhr4/Wk+WtScRg0w9lbSxmeMzHmfHy5mKStS6VrkGy3m9JWzgMxuvB/ybs+7LNGE3kwxwwxec8FtA2R59bL6sZhqCOVUBcvhRmIBJECend+JqwsCf/l62Zn5xtf+8vJpiytpv6I37bG+xv5gHbIt45u7h3B9q1E/+JuzeKbPGbiAkFeDe6c9ckR41Tu0rZUh10I1B/CvmH4bcS+I4t0hWH1YAmPOJpa1Eu/7YlZXRdlvf7AESLrfs7v7tQH9K+ygSvyhpH+Rf+5KqLbF/h2SBoT2R7eZ91L2xsOGvW1PIsJ8hqfgKOGaTTbCWR1bOkDvzgZUcVpZS4HDuTlHWMunPlQo+lvZP+If9hf/APLqn939oG9jrlxuWRgB0Cg6AUqY2M7ZeWYx5TV48km6l9EjN3TOmdmekXZ2ILC1eZssTNq6Ocx6yDuNEP6V4X+8P6j/AIVQHo6HaveSfa1PZGvspWXUTjKlQM8rTobtp+k7ZmHfJdvlWjNHCunTv0TwNab3pZ2SoBbEkZhI+ZvfuaVRXpTtAX7TdShHuP8A6qUcJaa46qJJJgVpxzcoKTGxdqzqUelTZWXNx2gzHzN7pz0yVlj0qbLdgq33LEwBwL/7lc7W7cZu5dB7P40zejjBBnuXSPVACnxMk/dS8mbZByAlOlZfyb04Usqi4ZZgoGR+ZMActNTRqqSxOIb5Tg7aas+Ks/qrcVmPllBq7ammyyyQ3SLxyclbPF31T5GuM0NxQCuo0+yuzbvqnyNcnXdhXkUNknsiQhmCOojoe6mTklVjAbxG6qpOWQI+wiimzdkcYK+bh5eUHWQdCD0Ioa1pggLAiDlIjUdZipARiuU6gCUI0MDmD8aCXXAVFrbMxYdQpabijXl2vztPjUq5ZV1KOJVtCD/PMVUmy7N20y3lch57AJ95I7o+2rQ2LtVcQmYaOujp1U94/NPQ/hWaUNoqUaAW0sPbssVYqOo5CR0NDjtCwo1dSPOm/bGFR0zOBKa69Qeh8Jg+ylv/AEPhrnrWgOpylh0M9a0YNDLLHcn5LUbBt3a1qJSCR1o7s+x8qw3FsmbiStxANTJLBh3aE+caeqaAbS3QYmcKwKRJRm7Wb6qmII7pIrVuptG5hr8FwC8IygmQZEHzB7+81oxY5aXJZaVB+zgcQRPCuRPMggd/M+FbdobIuoLf02dS7BQYtiToW5E6a9xKjqKbOOl20c7FGGY5VBP26CYGnh3kkj9l4sW7UMAeRDSFI16seSjmef0iATArq+rKrr9A+RQRSTAH8+M8q3LjrVvmwYxrEwPxrTv9tRluLbDKiZAzZJEsSYzzDTly8+VBLW01f5u4uZIhLi6uv4r+b7qzZ9c48RiC5NBVt5SbvYC8MdD9Idc0cvLWpO0sMLtoFIKjtWz4fSQ+IoC+Ba2SYBBHZcaqw9vI94NHty8SDcuW3yleG7w2fKGUaH5vtR3xXGyNzlv8i3y7PGxMOR2z6x7I/RHM/wA91btsY851taZACWM6ydF+/wCFNFnZlg5XDwjEAKFYiMyq8E6jtEkZtcuWdTSxa2It24LrB8hxNsFbgVS9s4hbJHZuFvWJ1gDsnWaVHG5StlJBL0ZYYW8BttQZ/q/j/dXu+kPYd25Gi5l8asD0YXg+zNrmZf5N2o/3V6PvqssFj3taLyNa5JuI2rQx3LjDpFamxUCSPChGI2hcbr7q3Yh2KCaTs+Qdtdn3E3yQYqOsAa863Wbg6it2JwKkSPdR2lww064BjOK2axpXp8P00FbA6gRPKjsI37B4i30IBIYhSPMx9sUY3l2MLbm7b7VtiAxjkx7x3GimyXQqrJl0BPkQD99SMM7es9stbMAyJUzqCRHiCDT9JgWeMpPh9Ap2Q9lqCEuGOwpjz5fYKg3b5u3mJ1VdB+FNA2UjIVtQCdV7p7vI8qVinBBDAgzqOs9RWHLp5Ypvd+gErQL3hYkZVnvMVYNnGGzupauHWLpnyOLYH2xSM+FF0NOhPQdPDWnzaezW/otbsJqxugD24on76djcacQmklQsLcDpE+R+yg6XuFcDdOo8PxFHtrYIWOGR6uUKfMCJ9v3UIx9uQTWaDTX0zKiFvNjQXVVMwJ8NdfwrTsfE8Jbrkam2VU+J7qiYTBG5eW2OZPw/9qP7bwqWhbtiGOrQR2ezrqOo0IjurRGKuONeRldRA+wbxV3gxK5Z8CwB+FO+N9HqG2t1T60CAfVPgOUHn5z4UD2Zs+3iBxbarbv2iCbaqwtXR1mJNpufaAy6agRJd9qY64LJQaAKD4gxmWfHSfdXUxYkva0rv9h8YCxuXs17F6+rjokHoRLUzWsfauMAtxGYrMBgTHfHOK025WzaxOr8RxaK8iCZKxzmYYax0761YPdzC2sg4cNHrzLAiCWBMldJiI5nQTXPy6J5M0lHhIVLA3Jih6W7euHPeHB/8NL261oKt68eaLC/pNpUzfvF3SwsXiC1p2APWDECRz0AI8627pOoCIRMsXb/AIV0+NDKDxY9j8FNOMKNL2ilkzzOnvp73Fw+TCz9ZifhSjtldEHVmk0+bGXJhU8pPtNYtVK8aXyxM3we9l25xtlzz4ltV8BxFJ95A9iirqqm9hL/AFmyx/vU/wCcVclaNG/a0Nw9Hm7yPka5j2LtssGR1BuKJUjTOI8ORrpu76p8jXJeEvJba3cObmJU9DEQeokU3PFSQ1jNZ2zadRxFKzMhlDAZRLAka6QfdRpN1rN9LVy1LZxIa3BQaElTDSGAB0KjkYnqsX7YF0NobWYGRzE6ajugkTUrYeJxBJs2zbBUOWbIiArbttPFOXtAWzcGvPN3mazKEe0VXwEzuTdS5nzghQwyMQHhVDGB1AUg+VSLux7uHBvjR0yxGqurFgVaOkr946Go+xt5r3DCnKYLHMVWe2FGVYHZACxpzzGfEs28RuyHlfYCOZPdPNm99G7X2DJ88njF7QS7ZBXTMYKnmI5jx/ChNmZKnqD9n8++imKIyiMpBJmNATp3cjyoZfSO0vT3jz6EeIrvaKKjhikNj0ENnCeXfzOnSSfYJPurVd3Vt3cWjAET866jQHU6nrqYn9KvWzHkqJAB1JPIcgZ9xMd1Me66TtDFgmVtWrKL4Fgzt/8AzrQ6pXS+ySN97BZSR1Me88/hNLm92IOEtqwVSXfJDch2WJJ1E8gI8aaxdz4oqPo/wH40M3ywiXr9m2SMtqblwHWc2iKZ5cifI0GSTSpdsgh7N3cuYwticbMNGULlGaAADEdlIAAEa8/EmX3XwoGTK4j6S3CDynl6vwoviLswORk+yQsH2dr3GswqKxBaQp0J8J1gEjpA9lHHBBLlWXQLw26yAFFe44eDkaDPcRAEN5Vot7rJgrhfE3TBEJat/liDqRcJ7NoajnJP1abW2qEBFhcgOnEJ+cI5Tm+iPBYHiaStsY1C5zyAn0h7zI/nlWPVYoQxuSVC5pJHzaF4XVuWrfzeftLbzErpyUk8/M0mbWxFzNBuXZU/WY9qQS3retIGvPsjuohiVuJfW8rZ7TfTXl+ifqkdxrZtvDrdHGUwRGeOo6P9xrnw9r/MFcDT6JCDs7bMT/Z+oj/VXqrV7dWh6LP/AKftg/8A2/8A0r1VkELaVoY2JtsW5K0RxohDWofNqIEmvt4NcERApUuypJtmzYSK2p50YZAOlL9tXtkZRRa5icyeNKmubBkfcJsC7ixce2yIEIUZp7TETGnIREnxHsW7+FYFlYFbikhlPMEcx/Gn/dC4FtXU6kh/PSCfZ2TWjbuBR3FwiCw1PiP/AE5fdW1wUcCyL9Q74sW9zbtxcSoBI0Jjpyj759lPHFuWriEaEQR4ZeQ7gNOXhWzcvddVs3MW+knJa15gHtN7SAo/RNTsVqeMR2QRlGnkOemvjp31r02RQwuTXyw0rPmOwj2VS5GVbolVJErrygakdZgaEdaAb13rWa0W1d40BEyOTkcoiNDzMeNMG1d6bzJkUwoAGY6sx7/qqfECTSHiMLce7xTJnkayZtZHLCq5A3InyoBykkgayuvtjSas/ZWuxLRP1m//AHNVScaJHvq1dht/2DbI6M8DyvvWGvbL8mKbtMAbcs23wFxxmLK9xgIMllVVCj2yYqvcJi8wg81MEdR5+XKrG2H83hntXdSzm8xHJSQNB4SF+NIW/wDsg2b/AB00W7zjo3Ue3n76kZwcti+CnTSBV641i8txean3jqPdXvF7Q4l4XHPZEDT6vWPYTUTFXma2rXBEkhT35Ylu4CSB51BuXOzHjWqMWmn5IkMmycScPfMagTIHXp/P8afsPhi9i+xksboJ74NtY+Ej2VXli2XsLeHr28quO9eSv9gPvq2txQL+DvKDLAIx9gZfsWunky8xkun/AH/ZpTpp+DxuuivgWz68K4G16QYEeMsD7K8bZskkaANBQ90yRM+3n4VL2Jb4S4tNOzdtn2G4k/Ca+4y2pymSdBJ6TMnzJYN7+gmJvSk5fqMdJspbf1B8scL3rP7Nf4V93ct9vyX7a274bOuDGsoDOzsbgCqSYY9yjkDK+wUe3c3fvqgJs3FZ2OjIywB35gI1765mXJvjuXkxTla4B+0lm6o7hTw+lu2ncoJ92n4+6l+1s5WDYpnThoJifXIklR10AWYn10+tI9jabX7HEBKO8jMOQaYlR1ga+Ejypc9BmyNJLor0ZMlbK2vxNo2LNv1bd63xD+dxFhPZqT4gDoZv2uX9y1OFxeHQjNnxVoZh43FAn3muoKdjx+nca6DiqtHm7yPka5Qw1jSD2rZEweaRqVnqBrHsrq+76p8jXLS22AnkSIIHlMjuI5UGZ9BM+5wtsONVAOae4nUH2E0aVRaweJv6g32GFUkEaaPeOvMFVtrP+Ya17BtAQ5+iYBjrzLR7R7vCmfaW3AyW1UNlVe1MasTLHTSPVAnnl6dX4dFKcVK+yRjaEnZHqSORYmiFs86Yre7q3kzWQttgPVghCTzBH0G68uR5R2mGf6KvKQGQgxM/R5Tow0OlIngnGdC5xdnrZ+MCyrE5W6idD3wOYopcwAYBkyxzJ7R9pKr7x8RQvZ271y6xMhR7Sfdy+NMmG3Jf6OJe2dDKAg/Bta14MmbGtso8BQckKrA4e6rsDw5nmDrp7uUwddKaNzsSnyrHuoIBFgyTIYcMkR4jUewVtx+6l4rluY3OvUXbSt16MCGHIdaSziTs/j22dXzqAjoe4tow6HtfbWjJk9Sm0OS3Dxunf4l+6/j9uv30Nv4sXBduHQ3Mz+OUdm2nn6vvPjQHYW3gmFuhZa5cJVQoJYA6E6coXr3xWzZmGuXdMyyOayMwjT1dYA8eVXcXlsklyEDilLE855qJ9xPd09/fFSIdtToByHIAe3U+331qGANo+MTOpPvIkH2RqNYNfc7nkSJ8/u0+FauPBDzj8SEVjoQupgifDkSSToJNIuOvo2ZHzSe0WWNDPUHmKN7f2sFQopzmdTMjnIUH7T4RrSteYFg0wSNT0PeD3VydZk3SUU+F/IuXLJOCu5FfKwu2mXK6rIbzjmCK+szWssdoDQj6yHvoOnYOhIJbyNEkxivmtNoTyPSY5/jWNxBaLE9G2FCYPbAXVGw4K+Rt3tPMVX7lUA01p89FpddnbXVolbJ07vm7tVvasPcuKg1ZjA7v4ACT7KbTpIZHok4K5xLkQIpkbCdkQNO+vOEwCWR82gd+txgT+ovJR8fspo3QwF267O+YoNMzZSk9VYZg3LqA0dwMEPnoJOO6Uq+ipK/IqfI6H7RCW9af8dsu04IlbbrI7JygkGOojv1jr7KFYLcSxdacTjAgP0Eyl57ixOX3A1l/CZYyp9FLGxf2XtELluco+zqPdRLaaFntovK5dVFPdnH3AD3U1XNwMFkizjGB/wAwKw/8OWKX8Xs58PiMMrlWRSclxDKkgNA8CJ5H7qdG8eOUJLhhqHga94MUBwcJa0VVGg6ACB8J99CN8McLdu3ZRZYkO2moA0UADmSZ93jULYuOF2/evE6KTH6K/wABWzBXDcm82t19eYi2CPVnkCBGvOAe/VzTyVij+oUlxRGt7KvXcuioSphWbtAnvCggQO89aH7Rtm12T6y9kjxGlGru37Vlsqw9w8oMqvixPP2fClHaOMLXDmMmSST399Y9TixQajD9RMkkR+FLEE68zVp7OxaWN3Ud+yqu3xxDR76qlwSc/wDPuqwdsqX3WUAEk3Rp/wB6NBCN2n8EaXQu7u7cfGYt0UKtoWbhOaZOgA5A6yRTFt7ADE4ZrfUjMn6Q1H4e2lncXA/JGN642roVCCNZIhZPLlM+FPe7NwEkZhMFQq52MaT+SVpjTnHMd8UuOjnlybocRXn5BWNySrpCjubh7qYZrd/DMgHJrqaMuZjENqO056ayNdKX9sbCsYcQLbXAxgMbhGUCOgHaJ1MkwJ5Vd21cIHUqZEzoIzAzOhA7JnXSOs8zVf7c2IT2ASyzI8SNNOrcyJH21rh/yGFZHjyK66ZpWPgVcFhmUC5bAgrlywxUjqCJ1nka+7Lxz2C9v1c2nXkDIWDr1ME1C2pjijm0MRcXISuVW0BBiOyJ0jWhNi9dLEG7nHOHZ2/5tR7K2LVY+NsaCVdJDHtPazBkM8mB08PLpRD+k+JxLKlnLZtIAGuPl073Yt2V6wNTHtpT2hiRAPOJzDy500tgxeSxh0TitaE3ASRYR2gk3CNXI5BR3mZEih1epgmqVr9gZtLsd9kYu2ezbxhuHuS+DPsUxX3be17S23VmJMEdqdDGhIOh9lVjvBtO/bu8FcQWRQshAqJPVQqaADl76dVxcODMLlU6AHoD7uh8CesVnjrWmrSp/wB+Bbzx4EzA4PFXuyiu6AxqJtpJmTMqupJk8pmmzerApZtottixCqupuEgAQBGRFAJnvHnNHE2/bW2lwtk5mQNUXPBUnkYMrB5wSZGhXd8+GqIygjPqsH1W7JZSDMBlh1IMjUSdBWnSyzLM/U6+g21fAI3Zuf1/CKet+2CPEOCD7CPjXSdcxbjKbu08KRMW7qsx6DWB7Sfvrp2r1LTyuvoW3bPN3kfI1zEom0BJPIaDuHxrpy76p8jXJ2z/AFBBiIYideWmnQQBp41gzq6ZTGi0+UIushBPLmZbWRoe1HsqQLpHaBII6yvxnQ+RBnyqLdYhx07Fs++2p+E17WWYLrJPITJ8BAJJ6AAEzXooRSikvgZ0h52ZYuKuUxooUZs6kISSFdXUA6jmSOhA1bPqxDOSyuT0KkMCGBmVLAkNBPQ6zJALGpuHsGyVW43zzAdi0qi6gKuwGIa00IIDQcyiQYLVp2irEmSDJ1kgzHOSQCx18I6kw2Xl5NRsyW1a+ikrMwmMFvll90mpL3cRc9UlR5x9n40Fxm07VlUuMrQeaqBnB58iRGhB1Px0qTsjes3zNpciKJYtBYmYERovXvp8skbpdlWS7m7F25rcuH+fOkvfTYGGSy5W/mcGAASwzc8rZZCmNYPSm3aOOW6IuHP+aTCHwZSQp+PkaXNp5LjBCgVVGiqAABMkADKO/p0q5RySVBJs9bB2PiMCA9uGUgSRqD5/iPjTtg7+HxIBuW0zxEkDN/wtz+NRN1LqJbyTKc4P0TrmI1MA8ysmCT31Lx+BQHPbIHU/VPj/ABoOH7ZLkptPsCbybJxFpWfC3C0ai1dAf2Ix7Q0+iSQarnam08SYW6xCsugACyI1mNSOmumlWvcxhZSv0RzJ5+z8aT9p7CsXbrXWDOWBBGaAI69Ijz+2lzxTkvY6QNcFfYrF92nQd/nWpVlcp86sJdiYewoXhqVYkFrihrhJ1Fq2h1Zx1GgWIY5iYi43ZGHcgFBbjqmjDXQFeUj84KecCgWik48MlccCGNQPzT/IrQzdoknxovtTYz2xxF7STzGhE9WXoOmhNCuE3WPMUiUHB1Lgotb0WMXwO1wBLfJxEakzavR5npXjcrdY2ka/iQwuN2VRlMhOpjoWOkHovjXv0P4lreD2tcXRksqymOq27xHnrXzZW9gxQyscl2PUHqt4rJJ9nMeIpunjG1YUejdta8gMZTA8RTpsHaS8ALaNqwsjshszjNyzMwjMeWXKfDNBAS/9EXrp7StHQaxHt/GKh4rE2sOciMr3Z1gyqfcW5aa+PdW3UvGsfuZH8hPfnEWrPavX5Zu0o0NxpMSAgjL2fWOnLvFKuyttYJzF1Lw11YCVjymah/6M415715ixJkknU1JuIiaAAVyPxbilCHSKeUcNm4vZDkKl58xIUKLd7MSe4Zdai76bJUWLlyxcLZBmI66a/CPhVdJtFrGJW9bCsVJhTyMgqeXgTRHam8WIvRZTLbBnMF8eYJMn7K0RyKUPe2GpNdjNu5uheOCD3OIq3RmaInKTyMjSR4daMbd3Ka5hzdwV+5cyJrh3yhjA1yZQJbwaeehHKg26HpFxeHtJh71sXrWoBbNxFA+iWnUCRBIJ+5o/0mC4uYZioPNT05dx5+Rq8ezJ7en/ACXu3Ipo3WBGuvt/nT7qMpZDNzkkaimvE7KTEXLl20uW88g/V7ejFQAO2wJ7z2jpqDQHFbv37bE8N9NJUTy8qyThfMefyFzVmtbIAiNKf8UhG7tsL/e/biDVZ28c+bK2vfpy8DVqG4Du+jDo5PuvtQ4ovc19C9rEfCqWIY8hovkOZHmfsFPe5aB2Am4xXrLBVGU9n1zn5nshQNCTOisn4NcqgDTQedHd39pmxdBiVBLaAZicpCqsjQTl5Ry18O9KFQ2x8GxxqNIfLuHA0HZGmugEQSFHkqs0eC9DFLm92MXC2Ll5oZ0ByiNM0AxPSM9oCfqMO4g5jdroA4UgEcQRPVQFXSPq9NOdVL6SNuG5hyJ/KZOzJgZC0c+Ryx765WHQwx3krn7FuTorrGWHhbjiOJJUnTNrBI8JnXwPdWjDYhkYQeRolvXjc+IOXVEAtoIIARRCqAeQUQPEgnrQ61aLOIHIT91E0kqYroN2cICWuEdgAkR0MaL5T8Ket7cUMLhRbtDKXOUd+slm/SPf3ml3CbNyY/5NPYLg+YC5wD7NK9ekdn+UICTk4YKjpMmT58q58vflivHYvJLe0hftYsradcqkMw7R5iByFOmyWLWQTzyD7KruSSR41Y2zFiyPBBR6hUheRAHeC8yoo6H3dnmPc8+yh2BS/i4shjlUhiza5YzR4k9poHgO7Ro34UHZ+FIiUuPPtLD7h8K27o4ZVw6Febak+P8ADlXQlmePTxflobKW2CD+5WyksXLKoP8AWoSTzY5hqauiqt2Db+et+Dr/AMwq0qx6aTlubBxO7PF31T5GuQcPjiVAVREazIPvnWuvr3qnyNcZpfMCBOg9nup842OHiw+fhMOttRJkmU7B+KmpqXLiMHRijLMMDDAnSQR1qJu+Bw7JbV4bTlAJkL7DnM97HuoxiLA7v5/n+TXbxTUoL8gwhsva6jLaVChYibkmZY5ZJ9Yt6pzEzmZyImiGz9o23vdnMA0oitByBWVUBAOXXNiDoIyqo5LSvhbfaBjlr4GNQDHlHtolg8KyHMNMnXyN0H3hjz7qDJjhywWjTvXreu+wDw7I099DdxcTDshJGbTXlPP28iPbW/EuWJY6liSfM86A7Pu5L7LMEGR9orzuPLU3NfNiE+bH5YLESfGSYA+E+0VFTDhnZgOhjw7ufeT7xW/B4gOuaNSMpjoepHdIg1utCJ01I19usaeZ+FehhNSW5eTQnZGwl4hlGneNBm9hiffNDNp7yfJ8wBZ2ZtLc6Is+swnnHTmdNQNaN4W20iQIiTpIP5wnl51XBtAu7zOZmafMk6Vj10kkmBN0PZ2ixthyAs6gBtCOjT0BEHXl1r61lnZHymRqAvracyoysSwg6AZh0B1iJsEo+FsuZZRcCGOi8ZgWP5oUOSTpC+cl9m30QlWWRlQwNWPZtEkEGeIhe2Bl1Mr1AjLqMmeUY7OuL+w4tVyQsfaZbOcEMIEOHdWIEx2xYtghdQEQqonUEmkt7rZiNBHReXwmnHeaw1mXTtpfysmIQqBdBEgEg6vAA1DAggqFggI6vmP8j4DT3V2NK7hYIa2e+kEeBBMqdIg6fClrbOxTbutw27J7Sg9AenjGo9lH8Eh/n+AofvXdi4uVu0EGZD5kj4Gk6+PsvyXLobPRYGGz9s5umH/6V6qs4hq1PRffzbO2zpBGH/6V6qvw+HLVy/HJIklNo4i7FvjXWHIKbjlfcTFMWz9iXFEkjyr5s3CW7Sqw1ajwxspHWsebK30KlLmgDj7xRhQ2/iWutC0XxGCL6HWtuB2cloFtDHMzCjzP4VcWq+w0gPa2UyHNGZo7I6DxPlUuxks28oALue0/U/gJqa207d0stsaACW6ewd1CsVeWSe6ilb4ZUn4PIxTBQoPOST3CnncvCG7h3JIBUk66Erl7IkHnMnQHkR1kIWDvsWDDKoBgdkE+ZnnTju9jDhyV4hbiqUGblJMgCI56rHWQKOEYuSi+L4/yFF0P2z8EQWiMygZ1OmYTo56ETKsDyYHVQSaSdtYl7WIKqAoHcGWJ1jKxgActJGnM0av755DxBalg2uuhUkFlMjmc1w90haTMXiluXWZMwUsSqknsjnl9nLyrq6HSPBa8BNtsl7Usq9t76orXFUsRBGYASQQIJMDn4R3Q3bJv8Tdu25CiWfRRA0vuPupW2URmGnWP4Ub2gfk+68L9G4yjyOKYffStZiUZXHtoCXToC7Fvi6oYEajr08POp9xIE8tPh7PMe6l30d2i9rEEH8mVbnpBEEDx6++m/C4fiCCeca8gBrJnoPuFOjq8bg5t/wDnv+/waIzuNsjbQV3XisRkZyFnmxzEswWOQkSZ7uc1VW9e1+JfhTKW5UeJ+kaePSPvBwVVLY7TLlQERlTq0dGYz/K0qba2CLWzrF0iHJk/8XSs+XUS2qMuG/Hx9f7+xWSaVIAugOtMm7OCUhW+k91EjuGYE/CaWMC0jL3Uy7o2i2JRZhVDv7QpE/EVly8REy6GHdm8b2Pe54M3sMKB7iPdRffnZIvWeIPXtAsPEc2Hwn2VA9HWH+buXerNkHkoB08y3wFGd8sRlwd8zEpl/WIX765cpf8AYSj4pCJP3cFe7vbMDWb2JY6WxoO9iNKasPiESz2mA7I5mh+zMA52URbUs925oB3A8/Kvuwtz7ubNiMsR2VzEkewafGtGScZbnJ9MNx3Ebbu0kuYVkXWHUzB5dYPnFTPR/js1s2oJKtPgAe+j+N3fwyWz8ocLbHaIJjQfmr2q+bD2zsywSbVuEjW6wCIT0BmWPt76k9S8uNRjFuuhjg3HkaNkrFy143E/5hVl1WtjFh79lhlCl7fqxl1YREc5ka1ZVM0LuLBw+aPF31T5GuM8zBAvJYnTqfGuzbnI+Vcy7Q2dausD4agaA+Nack9tWMcqBm7eOaVgfkxOY6zroINPODxK3gACFbuPf+b3j+NL9vDqggAKK13rsctPtocOreOXC4B9SnwOKWrVm2WusqA6drrpyA+kZ6CaXbm8/Ffg2lK2+rN67ETHLRRqdNSfDlS67EkliSe86n4152aIuT3Gm59XLImlwi5SsaTS9tLsYlG5ZhB/n3UfB0oJvInZV/qt/P3Vz8fdCl2Mu7+Il8n1hoPH/wBprzvNtR7MJbjiMJ11CLpqR9aRp76BYZzGYaRyP4VFupzZj4kk/E1uxapwx7F2MU6VEt9q37ilXusVPMaDN55QNKEbRuvIUKQp61P2bcDhmHIGB+NTcWgAEUpuT90nZV0+QvgMWLGCtKDrl1GkalrhEdSTkVh1V6F3dvtlGglSY8QxEmJ70smPza9Yy3mRNPoyPOQDPsBFDlwv8/z7T7K9Bgxx2Jjqs8jab8JrMnhsS2SZUEkEkBp589DzE9TOrCROpjxqZawM1Pw+zlGsT58qLJkjii5MprbyzLVxLay7AAD2nyHMmgLbPuYm4bjDICxPjHQL3wIE0xkgaIBPfGg/Gvh05nXvrjajVyzcLhC5ZGxt9H+DCYHaawINiPH8nd5nrSImDWNBT/uPcnBbTjpY/wCndpHtPpNYsnSoq3SA9m+Ecqx8q2YnEGQzNkToPpN5CoWPuJxJXtt07h+NaH0Oa4ZboOg86JQvkaoeWFcTtNiq65U6KOZ8++vmOxRe1LgxHZUcvM95oFcvy0k5j8BRTGXPmQ2eT3VHGmqLkeNiyiOW0nvrzat5219X7a02wCBrJOpr5iMVlELzq2rfAPngm4Z1NwqI/npXvbyHIGBIIOkHke8UFwjGc3dXvEYpn5nSr2VKwttD5sPHLjLc6cdR86ugnpxFHcevcZ7xPy/s4ocwEdT95Huqv7LsjB0JVlMhlMEHwIpy2bv1cgLiLKXY+mp4beZAUqT5AV1MWspVIsL4a7lhpgdY8NaY9vYJr+7Yt2hmLXJGoExiCTqdO+q62xvEjIUtIUB55iCY7hAEcqfMJtO5a3Ys3bZhuNGoBEHFsCNfCs2qyb5XDwn/AJKfyKO5huWbd6yQym5eRdQeQ5nXpE+6nDaQIW3ZtiGvsZP1bSwbn60qnkzd1ad28e+KTNdtW1IdgrqCCQJBOpMd2ncaMG8puZdMwGneFP2SR8K4M80lkbrrlrw2uhLltdopjfO47s919WOIZfABQAAPCIo1vttNX2dhwPpwfcKh734J3XKiFmOKu6KJ7u6gowV26trDnVlJAVSCdekjTTvnSukmpqMm+nZFzTBGAPbHt+w057mq4d2W075kKKwHZBMakmBGlMW7+5tiwoa4ouXOZLaqvgs6e2p2N3mw1ns58zD6NsT7JGg99Jy6jfcYKy5O+CXu3gmsWRbYCZJMctf5FS8cbeWbxTINe3GXT9Kvuy8QLtlLsRnEgEzGtIPpNxGa/atj6CSfNj+A+NY8UHlytdfItVuHZtr2ljL2gULyNFC/x6Ut43bVx0bPiVsTyW1Ex4se1PlFNu7GxLF3DWGZFdmaGloGW20KkEwQSrkiNRShtTdqxYuurLJNpsQAGBCpmMKQNQQIExFOhigvzGOEtu4Usdg711VCKxQuTxGMBzyDSx1H40N2zse7hmC3CMxEjKZBGYrp/wASsI8Ks6/dS5hMMlsACF0juYafA1G2ngb1vE2sSwQWUD5hMkBgSZBA5tHKdTWrHqFtd8Pml8k3xSNGzN4g13Z2GtqUjEYYOOmlxNB3iuj65P2JjDd2phXP0sXY93FWK6wp+KChGkXBUjzc5Hyqgl3ZxoA/qt79Q1f9ZVzxqfZco2c/Puzjf8Lf/UNa33Uxsf2W/P6BroWsoPQXyD6aObX3Sx/+Ev8A7Nq9rujjgB/VL/efmzXR9KuL3zt2MTi7eIy27OGSwxu9oybzFQCANADGvjV+ii9hWSbt4yP7Ne/UatWK3SxVwZWw16P0Gqy8Jv7ZNzEm4wWxa4HDIt3+MxvSArWzbmSw0CgmNTFS94d6+BYsYpEzYd7yJeZw9trSO2XiFXAIytAIIHOh/Dr5J6aKofdfFx/Zb0DkAhqFf3RxtwQcLfA7uG34Vbl/fe2mMv2HEWrItpnVbj3Ll5wX4VtLakvltiWiYkTFSxvzgS1pBek3lD24t3DK5yhJhexlYEMGjLBmIq1gS8lqCRTWD3QxiAIMLeAnXsN94rdf3axucKMJfIyzm4ZiZ5VaWL37tMMM2GOZb2KtWC123iEDLdzQ1om3Dk5TB9XTUjSplvfrAFblwXjw7QJa5w7vDMMEPDfJlunOQsISSTpNF6V9sjimVXh928aBHya8QehRq3HdzE/4W/8AqH7Yqw8ZvvbZsMMNDcTFrhrq3EuJct5kZ9UcKymAIkQQTUvC79YC5myXpCpcuA8O6FdbU8RrLFYvZYPqE0/HkyY1UZFpNdMrL+jmKH+zXv1D9teH3dxh/wBmvfqNVx7C25Yxdvi4di9uYzFHUHQHs5wMwgjUaTI6URoMilkdzdlON9lGLu1iwP7Ne/UatGK3WxpHYw9wH8625HwII+NX1WUv0kVsRVG4OxcZbwu0rd+wUa5ZAtiD2zkughZOupXu50j7S3R2jELhbzeAXT299dH1lX6S4CSo5hfc3aSDs4O+zHmcmg95qD/Qfah1OCxH6v8AGurKA78bfbA4K5ilQOUKAKSQDmuKnMd2afZRbUFZzku4u0/8DiP1f414O4+1Yj5FiI/R/jV+7wb+WbXEt2GVr9q6lt1dLwRc1xFILIhEkOI79ecGjeA3jw9689i0zM9ssrEW7nDDIQGUXCuQspIBAadavaSzni3uTtEL/Y78x9Woj7jbTP8AsV/9X+NXps7fR72Pu4VUw6LZum0y3b5XEsFWTet2uGQ1vu7UwJ0rbtH0iYNLF+9bZ7ptWmuKvDuqLoByzbYpDW88A3FkCZOlCoJFLgoq5uPtIKFGCvnv7P8AGtX9Btp/4K/+r/Gugn38wSJba49xC9viFTZv5kTNlz3Rw5tpmkBngHmNKm296sK157KuzNbBLlbV1rYhM5HEVcmbKQYmde+r2lt2c4/0I2n/AILEfq/xrF3K2nP9hxH6o/Guk9ibw4fFFxZZi1vLnV7dy26hhKkrdVWysJgxBiitTaiWcr3Nxtpn/Yr/AOr/ABq0MHuxiX3dsYNrTpe40shHaVflTOTH6OvtFWxWVNvFFPkqjH7OxVixGHwtx39VVC8h3k+740P3Z3c2ha4j3rbtcuEE6ExHTu91XPWVlWigotX2A8aZQG3tk7RuE27ODvpbJOZ8hBeTqdNQvxPwqJh9j4/DKVw2zcQ7kQ124sT+ioM5fCR41bY37s23xIxUWks4kYZGAdy7G3xBoikyQGAA7h1NfMJv1azXjeMILqW7KpbvtefNZF2Gt8PMGCkkwNORg82rTwSrwWopFE7T3c27iPyuGxJH1QsL+qOftpu3P9HNzNafE2Lo7JLKRABjkSD31au2N5eDewPYBw+LfhcQ5lZHZM1oZWE9sgiDBHwoSd97rXyqW7QsfL0wSu7XM1w5WN0qFQgFWEKSYMHUUU8KlHanX5F0LW2MFisOnDw2DvXCPVhewo56nr5Cq52lulta9da6+CvljH0BGnIDXlV94f0hbPe2LiXXZSQq5bF8liQxhAElyArFss5Y1iaiW/SFh2vMQ6/JBhDiuJkvi5AvG2TlNsApp5+Ea0GHTQxdd/IKgk7EbY+7+NOzrFs4a8l+3iCz5hANtrgZlI5sphCMuspXq5uniCpJw9w3HC22bKcxQsCZPOIEx4U9Y7f2wTZXDurM2Ls4a4t1LyMovBipVSkywWVJhTrrRHDb54O5xClx2W2GLOtm8UIVgrcNgmW7DECEJqS06fkOXKorq/u3ieIAuGuBFUAQunOh2/mxNoXALVnC3nHNiq6eAq5ti7as4pGeyxIRyjhkdHVhEqyXAGUwQdR1ohQx0kFJSvoWsSOZN19ydopjcK74O+qriLLMxXRVW4pJOvIAGum6ysrUMMrKysqEMrKysqEMpM3g3FOJuYu5x8nygYcRw5ycC5n+uM2bl0jxpzrKhBQ2nuWbt3G3Rdtf1r5P2LtjiIvBBGo4i5i0yCCpWNKnYXdcf6OOAvXXvg22ttdfVjmkyJJIyyMoJMBV1MUw1lQhXq+jFfk1m219buIt33vteu2Q6XWuaMLtovqMgQetoUBHdRXYu5nyfEW74uW+xhXw2S3YW2kvd4huBVaFE6ZYPeTTbWVCFe4X0bOptE4pYt4qxiRbt2SlkcIOCqW+KRba5nlmXTQdmt9rcC4MIcF8sPASDh4srxLbLdFxGdixF3KRliFkE9YIe6yoQR13AZrwxN7EB77Ym3iLrLayoy2rTWktKvEJTsse1J8qj4f0bMFt23xZe3h7N+zhRwgGTjoULXSHi6VUwICcqsCsqEIGwNnfJsNYw+bPwbSWs0RmyKFzRJiYmJNT6ysqEMrKysqEMrKysqEMoHvru/8AL8HcwoucLOUOfLmjJcV/VzCZyxz60crKhBPxm5Be3ik48fKMWmKnh+pkNs5Iz9qeH62nPlpUnZe6rWsdcxfGXK+f5q3a4YYswIa8Q5W66gQGyqddSaZ6yoQT9pblPicVbvYi+ly3aum7bUYdUvDQgWjeVpa0J5ZQTAk6TQzZ/owW3YvWOLZyvYewlxcKi3wGOjXbgabpAAEALPXXlYdZUIIuN3Fv3A5+WKrX8OMNiSMPpcQFsptg3fmnyMVJJYHnAr7c3AfjNctYs2F4TWk4NspcM2hbQ3nFyL2SMykqGBjtCKeayoQVNzd0GwV29de+LrXktI0Iy6283alrjsSwYTJOoJ6wGusrKhDKysrKhDKysrKhBKxW4Ze8bvHAnaFrHRw5/JoU4U5+szm6dxrztjcNr3ykrftjj3xe7dgubcWhbGQi6rK4IzB1IPSIp3rKhBf2vuzx8AMG1586ogTEN2rguW4K3jqJbMoJ11k661BtbkBcPgLC3f7JfXEM5STeYB889rslmdmmTHLWm6sqEKt2vuZiMNs/AYTD57/ye9cd71pQtwBhdICrx7bQTcCnLdXQdRpW/Cbg38RZzX2tYa4+AOCNm3blbYF8uj/lTJyZQVk6yc1WXWVCCNtH0fG7ivlPyiP6xg7+Xhz/AGVHXJOf6eeZjSORr7hdyMRawj4K1j2SxBFnLai4gNwPD3FuAuIzJ2chhz4U8VlQgu7nbsnBC+DcFw3rvFMIUCnIqkAFmMSpIkzBgk8yxVlZUIZWVlZUIf/Z)
"""

#CARREGANDO LIBRARIES
from sklearn import datasets
iris = datasets.load_iris()

iris.data

iris.target

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()
clf.fit(iris.data,iris.target)

clf.feature_importances_

iris.feature_names

#underfited: generaliza tudo
#good fit: equilibrio entre generalização e decorar = o ideal
#overfitted: decora dados
iris.data[0]
clf.predict([iris.data[0]])

#metricas de avaliação
from sklearn import metrics
pred = clf.predict(iris.data)
metrics.accuracy_score(iris.target, pred)

# 1.0 = 100% (nada é 100%: esta errado!) é preciso uma parte do dataset para aprender e a outra parte para testar! imagine voce fazer uma prova com os mesmos exericios estudados: voce vai apenas testar sua memoria, nao a inteligencia
clf.fit(iris.data[:120], iris.target[:120])
pred = clf.predict(iris.data[120:])
metrics.accuracy_score(iris.target[120:], pred)

# o problema aqui? pegamos apenas os primeiros modelos, a maquina nao entendera ou aprendera como treinar os ultimos, afinal o dataset esta ordenado! 80% esta ok, mas se aparecer um target 2(versicolour) ele nao acertara pois nao aprendeu o que é versicolour!
#a maquina aprendeu o que é virginia e setosa, nao versicolour = BALANCEIE OS DADOS!
iris.target[120:],pred

#validação cruzada é avaliar os dados com ele mesmo = média da validation cross
from sklearn.model_selection import cross_val_score
score = cross_val_score(clf,iris.data, iris.target, cv=10)
#cv é o numero de vezes da validação cruzada! ou seja, ensinou para 90% e treinou em 10%(cv)ele rodou 10x a forma randomica! por default rodaria 3! quanto maior o cv

import numpy as np
np.mean(score)

print(metrics.classification_report(iris.target[120:],pred))